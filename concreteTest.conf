[General Setup]

    save_path = ./
    input_features = AEA - B, % Air - B, Slump - B, WCM - B, WRA - B
    target_feature = CS 7 Day

#[CSV Setup]
#    setup_class = test.random_data.MakeRandomData
#    save_path = ../random_data
#    random_seed = 0

[Data Setup]

    [[Initial]]
    data_path = C:/Users/mvane/Documents/Skunkworks/Data/MASTML Batch B.csv
    weights = False #haven't tested weighting; may move

    #[[Extrapolation]]
    #data_path = ../random_data/random_test_data_noy.csv
    #weights = False
    
    #[[ExtrapolationNoD]]
    #data_path = ../random_data/random_test_data_noy_noD.csv
    #weights = False

    #[[InitialNoD]]
    #data_path = ../random_data/random_test_data_noD.csv
    #weights = False
    
    #[[InitialNoA]]
    #data_path = ../random_data/random_test_data_noA.csv
    #weights = False

    #[[Set2]]
    #data_path = ../random_data/random_set2_data.csv
    #weights = False


[Models and Tests to Run]

    models = gkrr_model
    test_cases = SingleFit_withy
    #Okay tests:
    #test_cases = SingleFit_withfilter,SingleFit_withy,SingleFit_noy
    #test_cases = SingleFitGrouped_test,SingleFitGrouped_match,SingleFitGrouped_nomatch,SingleFitGrouped_withfilter
    #test_cases = SingleFitPerGroup_test
    #test_cases = PredictionVsFeature_test
    #test_cases = KFoldCV_5fold, LeaveOutPercentCV_50, LeaveOneOutCV, LeaveOutGroupCV_cat
    #Okay tests, all:
    #test_cases = SingleFit_withfilter,SingleFit_withy,SingleFit_noy,SingleFitGrouped_test,SingleFitGrouped_match,SingleFitGrouped_nomatch,SingleFitGrouped_withfilter,SingleFitPerGroup_test,PredictionVsFeature_test, KFoldCV_5fold, LeaveOutPercentCV_50, LeaveOneOutCV, LeaveOutGroupCV_cat, ParamOptGA, SingleFit_fromparams, PlotNoAnalysis
    
    #Under development:
    #test_cases = ParamOptGA, SingleFit_fromparams

[Test Parameters]

    [[SingleFit_withy]]
    training_dataset = Initial
    testing_dataset  = Initial
    xlabel = Measured target
    ylabel = Target prediction
    stepsize = 1.0

[Model Parameters]

    [[linear_model]]
    fit_intercept = True

    [[decision_tree_model]]
    max_depth = 5
    min_samples_split = 2
    min_samples_leaf = 1
    split_criterion = mse

    [[gkrr_model]]
    alpha = 0.00139
    coef0 = 1
    degree = 3
    gamma = 0.518
    kernel = rbf

    [[lkrr_model]]
    alpha = 0.00518
    gamma = 0.518
    kernel = laplacian

    [[randomforest_model]]
    split_criterion = mse
    estimators = 100
    max_depth = 5
    min_samples_split = 2
    min_samples_leaf = 1
    max_leaf_nodes = 2
    jobs = 1

    [[adaboost_model]]
    estimators = 275
    max_depth = 12
    min_samples_split = 2
    min_samples_leaf = 1
    learning rate = 1
    loss function = linear

    #minmax, size, transfer_function are the verbatim arguments for neurolab.net.newff()
    #training_algorithm is the verbatim 'support train fcn' for neurolab.train omitting 'train_'
    #see: https://pythonhosted.org/neurolab/lib.html#module-neurolab.net
    #epochs,show,goal are neurolab.net.train() arguments
    #see: https://pythonhosted.org/neurolab/lib.html#train-algorithms-based-gradients-algorithms
    #NOTE: minmax is verbose b/c [[0,1]]*9 will have bad pointers
    [[nn_model_neurolab]]
    #minmax = [[0, 1],[0, 1],[0, 1],[0, 1],[0, 1],[0, 1],[0, 1],[0, 1],[0, 1]]
    minmax = [0, 1], [0, 1], [0, 1]
    size = 11, 1
    transfer_function = TanSig
    training_algorithm = bfgs
    epochs = 5
    show = False
    goal = 0.01[default]
